# Configurações do Classificador de APIs
# Copie este arquivo para .env e preencha com suas credenciais

# Provedor de LLM a usar (opcional, padrão: gemini)
# Opções: gemini, deepseek, groq
LLM_PROVIDER=gemini

# Chave de API do Google Gemini (obrigatório se LLM_PROVIDER=gemini)
# Obtenha sua chave em: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=sua_chave_api_aqui

# Chave de API do DeepSeek (obrigatório se LLM_PROVIDER=deepseek)
# Obtenha sua chave em: https://platform.deepseek.com
DEEPSEEK_API_KEY=sua_chave_api_aqui

# Chave de API do Groq (obrigatório se LLM_PROVIDER=groq)
# Obtenha sua chave em: https://console.groq.com
GROQ_API_KEY=sua_chave_api_aqui

# Caminho do dataset (opcional, padrão: fintechapis.csv)
DATASET_PATH=fintechapis.csv

# Número de execuções para cálculo de confiabilidade (opcional, padrão: 5)
NUM_RUNS=5

# Modelo do Gemini a usar (opcional, padrão: gemini-2.5-flash)
# Modelos disponíveis: gemini-2.5-flash, gemini-2.5-pro, gemini-2.5-flash-lite
GEMINI_MODEL=gemini-2.5-flash

# Modelo do DeepSeek a usar (opcional, padrão: deepseek-chat)
# Modelos disponíveis: deepseek-chat, deepseek-reasoner
DEEPSEEK_MODEL=deepseek-chat

# Modelo do Groq a usar (opcional, padrão: llama-3.3-70b-versatile)
# Modelos disponíveis: llama-3.3-70b-versatile, llama-3.1-8b-instant, mixtral-8x7b-32768
GROQ_MODEL=llama-3.3-70b-versatile

# Temperatura para geração (opcional, padrão: 0.0)
TEMPERATURE=0.0

# Diretório de saída dos resultados (opcional, padrão: results)
OUTPUT_DIR=results

# Número máximo de APIs a classificar (opcional, padrão: 0 = todas)
# Útil para testes rápidos. Exemplo: MAX_APIS=10 processa apenas as primeiras 10 APIs
MAX_APIS=0

